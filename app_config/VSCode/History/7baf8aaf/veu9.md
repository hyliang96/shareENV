---
title: ideas
date: 2021-02-08 00:00:00
updated: 2021-02-08 00:00:00
---

## ideas

借鉴gqm改进结构化图像生成， deep mind 发的

视觉的语法规则 sence parsing

桌子板凳等等object各自用specific gemerative model生成(用深度生成模型即可)，然后物体按照parse(语法分析)出语法/物理规律组织成自然/人建场景，还可以以一句话作为条件来生成相应的场景，如用在今日头条给一句话然后生成配图。朱松纯做过这个。这个方向应用很多，进一步，加上功能/建筑成本/造型规章的约束，建筑/家具/工业设计的自动设计。

视觉语法中是否涉及物理规律？如家具/建筑物/地形地貌不存在悬空物体

物体结构的解析。早期的基于结构的模式识别，解释性强。结构组织用这套方法;具体每个小物体用已有生成器，如gan 或其他。

手写文字用b样条的字形比用深度生成模型效果好，那风格迁移怎样不用深度生成模型搞？文字的语法是什么样的？
     在字体自动设计里，汉字笔画拼合，组件拼合，字体架构的语法？这样对于正楷字，只要设计笔画(如粗细 衬线);对于手写体，只要设计部件;然后即可自动拼合。是不是有上古的研究，未使用深度学习的那种，效果怎么样？

汉字生成更大的野心: 所有生造的字(不论独体字 还是合成字，或者在汉上学完去生成西夏文 韩文)都能生成好看的字形。

lda＋vae＋emb
低频词: encourage coorelation 看看关于低频词的文章？
emb聚类＋可视化
和word2vec在文档尺寸窗口的结果(聚类/最相关词/文档分类)来比较

用word2vec，我的emb来inti. fast text 的第一层，做文档分类，比分类正确率。去读一下论文。有专用的包。还有2gram的fast text，效果更好。1gram比rnn/cnn之类的方法差1-3%
fast text的github上有两片文章，一个是文档分类，一个是学word emb的新方法。

fasttext 可做文档分类 可比别的方法快100倍  而且效果好 适用于短文本 如影评

fasttext过来第一个线性变换后有木有激活？
木有。

小文集上的任务 要用word embedding，可从标准数据集上的词向量，adaptive 到这个任务上。

cnn中的kernel可否网络里别的层前传得到
应用 多任务的模型压缩

看RepFind: 利用用户笔画 相似物体检测。然后缩放图片时，这种物体长宽比不变。或者移动这种物体。利用轮廓带图(boundary bend map)找吻合的对象，用快速傅里叶变换来加速查找。

难点 物体重叠 缺失 变形 光照 深度
应用:
编辑一个问题 所有的都跟着变(如增减部件，网格变形，替换成别的物体)

启示: 即使不考虑光照 效果也能看

能不能用rcn替代repfind的物体检测？或者反过来替换？

可不可以做双镜头的rcn？克服深度消息。现在的双镜头相机 手机很多了。

胡事民组的scatch 2sence 统计场景中物体的位置关系
