---
title: 可解释狌
date: 2024-06-13 00:00:00
updated: 2024-06-13 00:00:00
---

# 可解释性

**AI 是黑箱，而 Anthropic 正找到方法一窥黑箱内部**

2024-05-22 00:25 by 帽子里的天空

https://www.wired.com/story/anthropic-black-box-ai-research-neurons-features/?utm_source=press.coop

AI 研究员 Chris Olah 过去十年沉迷于研究人工神经网络。他先后任职于 Google Brain 和 OpenAI，目前在他联合创办的 AI 创业公司 Anthropic 工作。他一直对 AI 内部如何工作十分感兴趣。随着生成式 AI 无处不在，AI 黑箱问题日益引人关注。大模型会随意捏造信息，如果我们能了解其内部如何工作，那么将有助于让它变得更安全。Olah 相信我们正实现这一目标。他的团队正通过对大模型逆向工程去了解它们为什么会产生特定输出。根据今天发表的论文，他们已经取得了显著进展。研究人员称，他们的做法是将人工神经元视为字母，字母本身没什么意义，只有按顺序组合起来才有意义。C 没有意义，但 Car 有。他们使用了被称为字典学习的技术去解释神经网络。


